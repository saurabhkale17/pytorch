{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "dM7eGrLn3Xlk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((50, 50)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0,5, ), (0.5, ))\n",
        "])"
      ],
      "metadata": {
        "id": "5BebCCTi4NEk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "trainset = torchvision.datasets.ImageFolder(root = '/content/data/train', transform=transform)\n",
        "testset = torchvision.datasets.ImageFolder(root = '/content/data/test', transform=transform)\n",
        "\n",
        "trainloader = DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(dataset=testset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "DDI_tbbI4p-S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageMultiClassClassification(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3) # BS, 32, 48 * 48\n",
        "    self.pool = nn.MaxPool2d(2, 2) # BS, 32, 24, 24\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3) # BS, 64, 22, 22\n",
        "    self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "    self.softmax = nn.Softmax()\n",
        "    self.fc1 = nn.Linear(64*4*4, 128)\n",
        "    self.fc2 = nn.Linear(128, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input image size = BS, 1, 50, 50\n",
        "    x = self.conv1(x) # BS, 32, 48, 48\n",
        "    x = self.pool(x) # BS, 32, 24, 24\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x) # BS, 64, 22, 22\n",
        "    x = self.pool(x) # BS, 64, 11, 11\n",
        "    x = self.relu(x)\n",
        "    x = self.conv3(x) # BS, 64, 9, 9\n",
        "    x = self.pool(x) # BS, 64, 4, 4\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "model = ImageMultiClassClassification()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXnsqrtz5cxh",
        "outputId": "9d53a2e2-0db8-44d0-c2a4-99ce4628fa42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageMultiClassClassification(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU()\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (softmax): Softmax(dim=None)\n",
            "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "skPgRs4i8srv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    input, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    y_hat = model(input)\n",
        "    # print(\"y_hat : \", y_hat)\n",
        "    loss = loss_fn(y_hat, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"loss : \", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIJmZiC0898F",
        "outputId": "dca254ea-9828-4f01-b85e-8825399acfe6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  tensor(0.7180, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.6748, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.7863, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.7326, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.5568, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.5520, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.8015, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.5524, grad_fn=<NllLossBackward0>)\n",
            "loss :  tensor(0.5515, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = []\n",
        "y_test_hat = []\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, y_test_temp = data\n",
        "    with torch.no_grad():\n",
        "        y_test_hat_temp = model(inputs).round()\n",
        "\n",
        "    y_test.extend(y_test_temp.numpy())\n",
        "    y_test_hat.extend(y_test_hat_temp.numpy())\n",
        "\n",
        "# %%\n",
        "acc = accuracy_score(y_test, np.argmax(y_test_hat, axis=1))\n",
        "print(f'Accuracy: {acc*100:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sJqaJjX9gUo",
        "outputId": "9afb12ac-952a-4d98-9d54-5e8dcb1bba21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.33 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, np.argmax(y_test_hat, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZaWr6Mm_8qu",
        "outputId": "fbc6a979-ed39-4a6b-d46e-40cd5845b8e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  0,  1],\n",
              "       [ 0, 20,  0],\n",
              "       [ 3,  0, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}